Challenges

Conceptual:

We did not encounter any major conceptual difficulties. Overall, we found the
description of the experimental setup and the evaluation in the original paper
quite clear. The network topology was well-described as were the parameters for
the videos tested.

Implementation:

There were several issues we faced in implementing the experiment to replicate the figures:

1) Lack of visibility into DRM-protected streams

We had initially planned to run the experiments some of the same services tested
in the original paper, which included NetFlix and Hulu. However, we ran into
difficulties with replicating the experiment on NetFlix for several reasons.
First, the streams of these services are protected by DRM, preventing us from
analyzing the contents of the streams and deducing, for example, the playback
length of the chunks requested by the client. Additionally, the web client does
not expose playback bitrate information, or allow the user to manually set the
video quality. Due to these reasons, we were unable to replicate the results on
NetFlix.

2) Playback rate extraction

We parse HTTP traffic to extract playback rate information. We currently do this
by using Firefox's ability to export network traffic in the HTTP Archive (HAR)
format, which we collect during streaming, and then process offline once the
streaming is complete. In order to generate the results, we map the requests for
segments to video quality deduced from the MPD manifest file. In some cases,
this manual mapping is not explicit in the manifest and must be deduced by
comparing streaming quality to the HTTP requests generated by the clients.

3) Clients not fully saturating links

We noticed that some clients, such as those of NetFlix, vimeo and dash.js do not
seem to fully saturate the network link created by mahimahi. We attribute
this to two reasons. First, in some cases, the clients initally download enough
segments to build up a playback buffer (during which time they saturate the
link), and afterwards, they download segments less frequently, leading to spikes
in the link utilization graph, rather than a steady saturation of the link.
Secondly, some players may be very conservative to avoid rebuffering events in
exchange for lower video quality. These players seem to  

4) Sensitivity to video viewport size

Video streaming clients may limit the bitrate of their playback based on the
size of the viewport in which the video is displayed. For example, if the size
is too small, clients may elect to pick a lower bitrate even though higher
bitrates are available. In order to prevent this from affecting the experimental
results, we require that the displayed video is maximized upon playback.
However, this approach may not be sufficient if this experiment is run in
screens that do not support sufficiently high resolutions.

5) Noisier results when running within a VM

We have provided instructions for a VM in order to enable smooth replication of
our results. However, we have noticed that the quality of the graphs produced is
sensitive to whether we are running the experiment in a VM or directly on a
physical machine. For example, we found that setting a limit on the downlink
queue to 15000 bytes with a droptail policy when running in a physical machine
allows us to generate smooth link utilization graphs.
However, if we set the same queue size in a VM, our graphs become noisier,
perhaps due to the network latency incurred by running within a VM.
Additionally, if we allow an unbounded queue on the downlink, we get cleaner
results in the VM, though not as smooth as with running on a physical machine.
